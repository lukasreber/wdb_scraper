{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('myvenv')",
   "metadata": {
    "interpreter": {
     "hash": "e4169395429c304b6be1848b8d4cd0e811385c9eb3dbc04355ed4a042331df65"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tutti.ch Webscraper\n",
    "## Mini Challenge 5 - wdb @ FHNW BSc Data Science\n",
    "### Author: Lukas Reber\n",
    "\n",
    "Script für Webscraping von tutti.ch mittels Selenium. Das Script sucht sämtliche Inserate welche mit dem definierten Suchbegriff gefunden werden und speichert folgende Attribute:\n",
    "\n",
    "* Titel\n",
    "* Beschreibung\n",
    "* Kategorie\n",
    "* Preis\n",
    "* Anzahl Aufrufe\n",
    "* Benutzername\n",
    "* Datum des Inserats\n",
    "\n",
    "Damit das Script funktioniert muss Chrome und der entsprechende Chrome Driver installiert sein"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using ChromeDriver 89\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys # used to send keys\n",
    "\n",
    "# https://selenium-python.readthedocs.io/waits.html\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import date,timedelta\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tutti_ad_links(searchterm):\n",
    "    \"\"\"Get a list of links from all Tutti ads from the defined search term.\n",
    "        This list can then be further used to scrape all information form the tutti ads.\n",
    "\n",
    "    Args:\n",
    "        searchterm (String): String to search ads on tutti.ch\n",
    "\n",
    "    Raises:\n",
    "        Exception: Navigation could not access search bar\n",
    "        Exception: Navigation could not access the number of search results\n",
    "\n",
    "    Returns:\n",
    "        list: List of links to all Tutti ads returned from the specific search term\n",
    "    \"\"\"    \n",
    "    # defining the browser to be used\n",
    "    PATH = './ChromeDriver/chromedriver'\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "\n",
    "    # Website to be used - this is hardcoded since the function wouldn't work for another website anyways\n",
    "    driver.get(\"https://tutti.ch\")\n",
    "\n",
    "    # accept cookie disclaimer\n",
    "    cookie = driver.find_element_by_id('onetrust-accept-btn-handler')\n",
    "    cookie.click()\n",
    "\n",
    "    # access the search bar to search for defined term\n",
    "    try:\n",
    "        root = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"root\"))\n",
    "        )\n",
    "        search = root.find_element_by_name('search')\n",
    "        search.clear()\n",
    "        search.send_keys(searchterm)\n",
    "        search.send_keys(Keys.RETURN)\n",
    "\n",
    "    except:\n",
    "        driver.quit()\n",
    "        raise Exception('Excecution failed on search bar navigation')\n",
    "\n",
    "    # getting the number of search results the search term delivered\n",
    "    try:\n",
    "        root = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"root\"))\n",
    "        )\n",
    "\n",
    "        # wait some more for everything to load\n",
    "        sleep(5)\n",
    "\n",
    "        # find number of search results by css selector (for unknown reasons xpath contains doesnt work here)\n",
    "        # find_element_by_xpath(\"//*[contains(text(),'Inserate aus der ganzen Schweiz')]\")\n",
    "        num_results = root.find_element_by_css_selector('h1')\n",
    "        \n",
    "        # using regex to only get the number from the string\n",
    "        n = re.findall(r'\\d+',num_results.text)\n",
    "        \n",
    "        # return the number of search results\n",
    "        print(f'number of search results: {n[0]}')\n",
    "        \n",
    "    except:\n",
    "        driver.quit()\n",
    "        raise Exception('Excecution failed on getting the number of search results: no results')\n",
    "\n",
    "    # getting the links from all ads\n",
    "    links = []\n",
    "    condition = True\n",
    "    while condition:\n",
    "        try:\n",
    "            root = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"root\"))\n",
    "            )\n",
    "            # find all titles by xpath search\n",
    "            ads = root.find_elements_by_xpath('//a[@data-automation=\"ad-subject\"]')\n",
    "\n",
    "            # from each title get the href link\n",
    "            for ad in ads:\n",
    "                links.append(ad.get_property('href'))\n",
    "\n",
    "            # move to next page until there is are no more pages left\n",
    "            try:\n",
    "                element = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '/html/body/div[2]/div/div/div/div[2]/div/div[1]/div/div/div/div[1]/div/div[6]/nav/ul/li[last()-1]/a'))\n",
    "                )\n",
    "                element.click()\n",
    "\n",
    "                # do some more waiting, just to be sure\n",
    "                sleep(5)\n",
    "            except:\n",
    "                condition=False\n",
    "        except:\n",
    "            driver.quit()\n",
    "\n",
    "    # close browser when everything is done\n",
    "    driver.close()\n",
    "    driver.quit()\n",
    "\n",
    "    # return list of links\n",
    "    return links\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ad_data(links):\n",
    "    \"\"\"Get all defined attributes from each tutti ad\n",
    "        \n",
    "\n",
    "    Args:\n",
    "        links (List): List of tutti urls for each ad to be scraped\n",
    "\n",
    "    Raises:\n",
    "        Exception: could not find specific data\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing id, title, price, place, user, description, category, dateadded and views of each ad\n",
    "    \"\"\"    \n",
    "    # defining the browser to be used\n",
    "    PATH = './ChromeDriver/chromedriver'\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "\n",
    "    # Open website to accept cookie message\n",
    "    driver.get(\"https://tutti.ch\")\n",
    "    #sleep(5)\n",
    "\n",
    "    # accept cookie disclaimer\n",
    "    cookie = driver.find_element_by_id('onetrust-accept-btn-handler')\n",
    "    cookie.click()\n",
    "\n",
    "    # create empty dataframe\n",
    "    df = pd.DataFrame([], columns=['id','title','price','zip','user','description','category','dateadded','views'])\n",
    "\n",
    "    # iterate through all links and get the defined information\n",
    "    for link in links:\n",
    "        driver.get(link)\n",
    "        try:\n",
    "            root = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"root\"))\n",
    "            )\n",
    "            dict = {}\n",
    "            dict['id'] = link.split('/')[9]\n",
    "            dict['title'] = root.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/div[1]/div[1]/div/div[1]/div[1]/div[1]/h1').text\n",
    "            dict['price'] = root.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/div[1]/div[1]/div/div[1]/div[2]/div[1]/h2').text.replace('\\'','')[:-2]\n",
    "            dict['zipcode'] = root.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/div[1]/div[1]/table/tbody/tr[4]/td/dd').text\n",
    "            try:\n",
    "                dict['user'] = root.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/div[2]/div[2]/div[1]/div/div[2]/h4').text\n",
    "            except:\n",
    "                dict['user'] = None\n",
    "            dict['description'] = root.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/div[1]/div[1]/table/tbody/tr[2]/td').text.replace('\\n','<br>')\n",
    "            dict['category'] = root.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/div[1]/div[1]/table/tbody/tr[1]/td[1]/div/a').text\n",
    "            dict['dateadded'] = root.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/div[1]/div[1]/div/div[1]/div[2]/div[2]/div[1]/span').text\n",
    "            if 'Heute' in dict['dateadded']:\n",
    "                dict['dateadded'] = date.today().strftime(\"%d.%m.%Y\")\n",
    "            if 'Gestern' in dict['dateadded']:\n",
    "                dict['dateadded'] = (date.today() - timedelta(days = 1)).strftime(\"%d.%m.%Y\")\n",
    "            dict['views'] = root.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/div/div/div/div[1]/div[1]/div[1]/div/div[1]/div[2]/div[2]/div[2]/span').text\n",
    "            \n",
    "            df = df.append(dict, ignore_index=True)\n",
    "\n",
    "            # check if user exists\n",
    "            if not search_user(dict['user']):\n",
    "                create_aduser(dict['user'])\n",
    "\n",
    "            # send ad to database        \n",
    "            create_ad(dict['id'],dict['title'],dict['description'][0:5000],dict['price'],dict['zipcode'],dict['category'],dict['dateadded'],link,dict['views'],dict['user'])\n",
    "\n",
    "        except:\n",
    "            driver.close()\n",
    "            driver.quit()\n",
    "            raise Exception('could not find ad or specific attribute')\n",
    "    \n",
    "    # close open connection\n",
    "    driver.close()\n",
    "    driver.quit()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ad(nr,title,description,price,zipcode,category,dateadded,url,views,user):\n",
    "\n",
    "    query = \"\"\"\n",
    "    mutation {\n",
    "    createAd(\n",
    "        nr: %s,\n",
    "        title: \"%s\",\n",
    "        description: \"%s\",\n",
    "        price: %s,\n",
    "        zipcode: %s,\n",
    "        category: \"%s\",\n",
    "        dateadded: \"%s\",\n",
    "        url: \"%s\",\n",
    "        views: %s,\n",
    "        userName: \"%s\"\n",
    "    ) {\n",
    "        id\n",
    "        nr\n",
    "        title\n",
    "        description\n",
    "        price\n",
    "        zipcode\n",
    "        category\n",
    "        dateadded\n",
    "        url\n",
    "        views\n",
    "        user {\n",
    "        id\n",
    "        }\n",
    "    }  \n",
    "    }\n",
    "    \"\"\" % (nr,title,description,price,zipcode,category,dateadded,url,views,user)\n",
    "\n",
    "    url = 'http://127.0.0.1:8000/graphql/'\n",
    "    r = requests.post(url, json={'query': query})\n",
    "    return r.status_code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_user(user):\n",
    "\n",
    "    query = \"\"\"\n",
    "    {\n",
    "        adusers(name: \"%s\") {\n",
    "            id\n",
    "            name\n",
    "        }\n",
    "    }\n",
    "    \"\"\" % (user)\n",
    "\n",
    "    url = 'http://127.0.0.1:8000/graphql/'\n",
    "    r = requests.post(url, json={'query': query})\n",
    "    if len(json.loads(r.text)['data']['adusers']):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aduser(name):\n",
    "\n",
    "    query = \"\"\"\n",
    "    mutation {\n",
    "        createAduser(\n",
    "            name: \"%s\"\n",
    "        ) {\n",
    "            name\n",
    "        }  \n",
    "    }\n",
    "    \"\"\" % (name)\n",
    "\n",
    "    url = 'http://127.0.0.1:8000/graphql/'\n",
    "    r = requests.post(url, json={'query': query})\n",
    "    return r.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of search results: 135\n"
     ]
    }
   ],
   "source": [
    "# getting links form all tutti ads\n",
    "links = get_tutti_ad_links('hellblau grau schwarz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_ad_data(links[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id                                              title price  zip  \\\n",
       "0  35493803  Buba Light, Designer Outdoor Leuchte, Neu, 64%...   558  NaN   \n",
       "1  31937422             Offroad Klappanhänger von TPV Böckmann  8260  NaN   \n",
       "\n",
       "     user                                        description  \\\n",
       "0  Andres  Designer Gefäss, Leuchte, Lampe, Topf von BUBA...   \n",
       "1    None  Geht überall hin, wo dein Auto auch geht\\nCamp...   \n",
       "\n",
       "            category   dateadded views zipcode  \n",
       "0  Gartenausstattung  18.03.2021    16    9443  \n",
       "1        Autozubehör  18.03.2021    58    6017  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>price</th>\n      <th>zip</th>\n      <th>user</th>\n      <th>description</th>\n      <th>category</th>\n      <th>dateadded</th>\n      <th>views</th>\n      <th>zipcode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35493803</td>\n      <td>Buba Light, Designer Outdoor Leuchte, Neu, 64%...</td>\n      <td>558</td>\n      <td>NaN</td>\n      <td>Andres</td>\n      <td>Designer Gefäss, Leuchte, Lampe, Topf von BUBA...</td>\n      <td>Gartenausstattung</td>\n      <td>18.03.2021</td>\n      <td>16</td>\n      <td>9443</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31937422</td>\n      <td>Offroad Klappanhänger von TPV Böckmann</td>\n      <td>8260</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>Geht überall hin, wo dein Auto auch geht\\nCamp...</td>\n      <td>Autozubehör</td>\n      <td>18.03.2021</td>\n      <td>58</td>\n      <td>6017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}